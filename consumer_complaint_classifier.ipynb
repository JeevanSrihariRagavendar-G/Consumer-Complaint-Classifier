"""
Consumer Complaint Text Classification
--------------------------------------
This project classifies consumer complaints into one of four categories:
1. Credit Reporting
2. Debt Collection
3. Consumer Loan
4. Mortgage

Dataset Source:
https://catalog.data.gov/dataset/consumer-complaint-database
"""


# Import Libraries

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import re
import nltk
import warnings
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from nltk.tokenize import word_tokenize
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.metrics import (
    classification_report,
    confusion_matrix,
    accuracy_score,
    precision_score,
    recall_score,
    f1_score
)
warnings.filterwarnings('ignore')


# Download NLTK resources
nltk.download('stopwords', quiet=True)
nltk.download('wordnet', quiet=True)
nltk.download('punkt', quiet=True)
nltk.download('omw-1.4', quiet=True)
print("Libraries imported successfully.")


# Load and Explore the Dataset
print("\nLoading dataset (first 50,000 rows for faster processing)...")
url = "https://files.consumerfinance.gov/ccdb/complaints.csv.zip"
df = pd.read_csv(url, compression='zip', nrows=50000)
print(f"Dataset loaded successfully with {df.shape[0]} rows and {df.shape[1]} columns.")
print("\nTop complaint categories:")
print(df['Product'].value_counts().head(10))



# Filter for Selected Categories
selected_categories = [
    'Credit reporting, credit repair services, or other personal consumer reports',
    'Credit reporting, repair, or other',
    'Debt collection',
    'Consumer Loan',
    'Vehicle loan or lease',
    'Student loan',
    'Mortgage',
    'Home equity loan or line of credit (HELOC)'
]

df = df[df['Product'].isin(selected_categories)].copy()
def map_category(x):
    if 'Credit' in x:
        return 0
    elif 'Debt' in x:
        return 1
    elif any(k in x for k in ['Consumer', 'Vehicle', 'Student']):
        return 2
    elif any(k in x for k in ['Mortgage', 'Home']):
        return 3
    return -1
df['Category'] = df['Product'].apply(map_category)
df = df[df['Category'] != -1]
category_names = ['Credit Reporting', 'Debt Collection', 'Consumer Loan', 'Mortgage']
print("\nCategory distribution:")
print(df['Category'].value_counts())


# Plot category distribution
plt.figure(figsize=(7, 4))
sns.countplot(x='Category', data=df, palette='Set2')
plt.title('Distribution of Complaint Categories')
plt.xticks(ticks=[0, 1, 2, 3], labels=category_names, rotation=20)
plt.tight_layout()
plt.savefig('category_distribution.png', dpi=300)
plt.show()



# Clean and Preprocess Text

print("\nCleaning complaint narratives...")
df = df.dropna(subset=['Consumer complaint narrative'])
lemmatizer = WordNetLemmatizer()
stop_words = set(stopwords.words('english')) - {'credit', 'debt', 'loan', 'mortgage'}
def clean_text(text):
    text = text.lower()
    text = re.sub(r'http\S+|www\S+|\S+@\S+', '', text)
    text = re.sub(r'[^a-z\s]', ' ', text)
    text = re.sub(r'\s+', ' ', text).strip()
    tokens = [lemmatizer.lemmatize(w) for w in word_tokenize(text)
              if w not in stop_words and len(w) > 2]
    return ' '.join(tokens)
df['cleaned_text'] = df['Consumer complaint narrative'].apply(clean_text)
df = df[df['cleaned_text'].str.len() > 10]
print(f"Cleaned dataset size: {df.shape[0]} complaints")



# Train-Test Split and Vectorization
X = df['cleaned_text']
y = df['Category']
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)
tfidf = TfidfVectorizer(max_features=5000, min_df=5, max_df=0.8, ngram_range=(1, 2))
X_train_tfidf = tfidf.fit_transform(X_train)
X_test_tfidf = tfidf.transform(X_test)
print("TF-IDF vectorization completed.")



# Model Training
models = {
    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),
    'Naive Bayes': MultinomialNB(),
    'Random Forest': RandomForestClassifier(n_estimators=120, random_state=42),
    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),
    'SVM (Linear)': SVC(kernel='linear', probability=True, random_state=42)
}
results = {}
print("\nTraining models and evaluating performance...\n")
for name, model in models.items():
    model.fit(X_train_tfidf, y_train)
    y_pred = model.predict(X_test_tfidf)
    results[name] = {
        'Accuracy': accuracy_score(y_test, y_pred),
        'Precision': precision_score(y_test, y_pred, average='weighted'),
        'Recall': recall_score(y_test, y_pred, average='weighted'),
        'F1': f1_score(y_test, y_pred, average='weighted'),
        'Model': model,
        'Pred': y_pred
    }
    print(f"{name:<20} | Accuracy: {results[name]['Accuracy']:.3f} | F1: {results[name]['F1']:.3f}")



# Model comparison dataframe
comparison = pd.DataFrame([
    [m, v['Accuracy'], v['Precision'], v['Recall'], v['F1']]
    for m, v in results.items()
], columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1']).sort_values('F1', ascending=False)
best_model_name = comparison.iloc[0]['Model']
best_model = results[best_model_name]['Model']
print("\nModel Performance Summary:\n")
print(comparison.to_string(index=False))


# Plot model comparison
plt.figure(figsize=(8, 5))
sns.barplot(data=comparison, x='Model', y='F1', palette='pastel')
plt.title('Model Comparison (F1 Score)')
plt.xticks(rotation=30)
plt.tight_layout()
plt.savefig('model_comparison.png', dpi=300)
plt.show()


# Evaluate Best Model
y_pred_best = results[best_model_name]['Pred']
print(f"\nBest Model: {best_model_name}")
print("\nClassification Report:")
print(classification_report(y_test, y_pred_best, target_names=category_names))


# Confusion Matrix
cm = confusion_matrix(y_test, y_pred_best)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=category_names, yticklabels=category_names)
plt.title(f'Confusion Matrix - {best_model_name}')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.tight_layout()
plt.savefig('confusion_matrix.png', dpi=300)
plt.show()


# Test on New Example Complaints
sample_texts = [
    "I have been trying to correct errors on my credit report for months.",
    "A debt collector keeps calling me about a loan I don't owe.",
    "The personal loan interest rate is much higher than agreed.",
    "My mortgage company refuses to modify my loan despite hardship."
]
print("\nTesting the model with new example complaints:\n")
for text in sample_texts:
    cleaned = clean_text(text)
    vector = tfidf.transform([cleaned])
    pred = best_model.predict(vector)[0]
    print(f"Complaint: {text}\nâ†’ Predicted Category: {category_names[pred]}\n")
print("executed successfully.")
